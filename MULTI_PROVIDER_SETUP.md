# OllamaCraft - Configuraci√≥n Multi-Proveedor

Este documento explica c√≥mo configurar y usar el nuevo sistema multi-proveedor de OllamaCraft que soporta Ollama, Anthropic Claude y OpenAI.

## üéØ Caracter√≠sticas Principales

- **M√∫ltiples Proveedores**: Soporte para Ollama (local), Claude (Anthropic) y OpenAI
- **Selecci√≥n de Modelo**: Configura cualquier modelo de cada proveedor
- **Detecci√≥n Inteligente**: El agente decide cu√°ndo responder usando IA contextual
- **Nombre Configurable**: Personaliza el nombre de tu agente
- **Historial Unificado**: Mantiene contexto entre conversaciones
- **Herramientas MCP**: Integraci√≥n completa con todas las herramientas

## üìù Configuraci√≥n Completa

### 1. Configuraci√≥n B√°sica del Agente

```yaml
ai:
  provider: "claude"          # Opciones: "ollama", "claude", "openai"
  agent-name: "Steve"         # Nombre personalizable del agente
  system-prompt: "Eres {agent_name}, un asistente √∫til en un mundo de Minecraft que puede ayudar a los jugadores con comandos, construcci√≥n, crafting y administraci√≥n del servidor."
  temperature: 0.7            # Creatividad del modelo (0.0-1.0)
  max-context-length: 50      # M√°ximo mensajes en historial
```

### 2. Configuraci√≥n por Proveedor

#### Ollama (Local)
```yaml
ollama:
  model: "llama3.1"                    # Modelo local de Ollama
  base-url: "http://localhost:11434/api"
  timeout-seconds: 60
  max-retries: 3
```

**Modelos recomendados de Ollama:**
- `llama3.1` - Uso general (recomendado)
- `llama3:70b` - Mayor capacidad, m√°s lento
- `codellama` - Especializado en c√≥digo
- `phi3` - R√°pido y ligero

#### Anthropic Claude
```yaml
claude:
  model: "claude-3-5-sonnet-20241022"   # Modelo de Claude
  api-key: "sk-ant-api03-..."           # Tu API key de Anthropic
  base-url: "https://api.anthropic.com/v1"
  timeout-seconds: 60
  max-retries: 3
```

**Modelos disponibles de Claude:**
- `claude-3-5-sonnet-20241022` - Excelente tool calling (recomendado)
- `claude-3-5-haiku-20241022` - R√°pido y econ√≥mico
- `claude-3-opus-20240229` - M√°xima capacidad
- `claude-sonnet-4-20250514` - √öltimo modelo Claude 4 (beta)
- `claude-opus-4-20250514` - Claude 4 m√°s avanzado (beta)

#### OpenAI
```yaml
openai:
  model: "gpt-4o"                      # Modelo de OpenAI
  api-key: "sk-..."                    # Tu API key de OpenAI
  base-url: "https://api.openai.com/v1"
  organization: "org-..."              # Opcional: ID de organizaci√≥n
  timeout-seconds: 60
  max-retries: 3
```

**Modelos disponibles de OpenAI:**
- `gpt-4o` - √öltima versi√≥n GPT-4 (recomendado)
- `gpt-4o-mini` - Versi√≥n r√°pida y econ√≥mica
- `gpt-4-turbo` - Versi√≥n turbo de GPT-4
- `gpt-3.5-turbo` - Econ√≥mico para uso b√°sico

### 3. Sistema de Detecci√≥n Inteligente

```yaml
chat:
  monitor-all-chat: false              # Monitor todo el chat vs solo menciones
  trigger-prefix: "Steve, "            # Prefijo tradicional de activaci√≥n
  response-format: "[Steve] &a%message%"
  
  detection:
    intelligent-detection: true        # Habilitar detecci√≥n con IA
    detection-provider: "claude"       # Proveedor para an√°lisis contextual
    detection-timeout-seconds: 3       # Timeout para an√°lisis IA
    confidence-threshold: 0.6          # M√≠nimo confidence para responder
    fallback-to-prefix: true          # Usar prefijo si falla la IA
    cache-decisions: true             # Cache para mejor rendimiento
    cache-duration-minutes: 5         # Duraci√≥n del cache
```

### 4. Integraci√≥n MCP (Opcional)

```yaml
mcp:
  enabled: false                      # Habilitar solo si tienes servidor MCP
  server:
    url: "http://localhost:25575"     # URL del servidor MCP
    api-key: "your-secure-api-key"    # API key del servidor MCP
  tools:
    enabled: true                     # Habilitar herramientas
  bridge:
    debug: false
    timeout-ms: 30000
    retries: 3
```

### 5. Test de Inicio

```yaml
startup-test:
  enabled: true                       # Test autom√°tico al iniciar
  delay-seconds: 5                    # Espera antes del test
  broadcast-to-players: true          # Anunciar a jugadores conectados
```

## üöÄ Configuraci√≥n R√°pida

### Para empezar con Claude (Recomendado)
```yaml
ai:
  provider: "claude"
  agent-name: "Assistant"

claude:
  model: "claude-3-5-sonnet-20241022"
  api-key: "TU_API_KEY_AQUI"

chat:
  detection:
    intelligent-detection: true
    detection-provider: "claude"
```

### Para empezar con OpenAI
```yaml
ai:
  provider: "openai"
  agent-name: "ChatGPT"

openai:
  model: "gpt-4o"
  api-key: "TU_API_KEY_AQUI"

chat:
  detection:
    intelligent-detection: true
    detection-provider: "openai"
```

### Para usar solo Ollama (Local)
```yaml
ai:
  provider: "ollama"
  agent-name: "Llama"

ollama:
  model: "llama3.1"

chat:
  detection:
    intelligent-detection: true
    detection-provider: "ollama"
```

## üîß Funcionamiento del Sistema

### Detecci√≥n Inteligente

El sistema analiza cada mensaje del chat para decidir si el agente debe responder:

1. **An√°lisis r√°pido** (1ms): Patrones como preguntas, saludos, menciones
2. **An√°lisis contextual** (100ms-3s): Usa IA para analizar contexto y intenci√≥n
3. **Decisi√≥n final**: Combina ambos an√°lisis con confidence score

### Ejemplos de Detecci√≥n

**‚úÖ Responder√≠a a:**
- "¬øC√≥mo hago una espada de diamante?"
- "Assistant, help me with redstone"
- "I'm confused about this build"
- "Hola, necesito ayuda"

**‚ùå No responder√≠a a:**
- "lol that's funny" (conversaci√≥n casual)
- "/tp spawn" (comando)
- "hey everyone what's up" (saludo general)

### Historial y Contexto

- Mantiene historial de conversaci√≥n por jugador
- El agente recuerda interacciones previas
- Contexto compartido entre todos los proveedores
- Cache inteligente para mejor rendimiento

## üõ°Ô∏è Seguridad

- API keys nunca se muestran en logs
- Validaci√≥n de entrada para prevenir inyecci√≥n
- Timeouts configurables para evitar bloqueos
- Fallbacks autom√°ticos si un proveedor falla

## üîç Troubleshooting

### El agente no responde
1. Verificar que `intelligent-detection: true`
2. Verificar API key del proveedor
3. Verificar `confidence-threshold` (bajar a 0.4 para testing)
4. Revisar logs del servidor

### Errores de API
1. Verificar conectividad a internet
2. Verificar validez de API keys
3. Verificar quotas/l√≠mites de rate de la API
4. Revisar configuraci√≥n de `timeout-seconds`

### Performance Issues
1. Habilitar `cache-decisions: true`
2. Ajustar `detection-timeout-seconds`
3. Usar modelo m√°s r√°pido para detecci√≥n
4. Configurar `fallback-to-prefix: true`

## üìû Obtener API Keys

### Anthropic Claude
1. Visita https://console.anthropic.com/
2. Crea una cuenta
3. Genera una API key en "Account Settings"
4. Formato: `sk-ant-api03-...`

### OpenAI
1. Visita https://platform.openai.com/
2. Crea una cuenta  
3. Genera una API key en "API Keys"
4. Formato: `sk-...`

### Ollama (Local)
1. Instala Ollama: https://ollama.ai/
2. Ejecuta: `ollama pull llama3.1`
3. Inicia el servidor: `ollama serve`
4. No requiere API key

## üéâ ¬°Listo!

Tu servidor Minecraft ahora tiene un asistente IA inteligente que puede:
- Responder preguntas contextuales
- Ayudar con comandos y crafting
- Ejecutar herramientas del servidor (con MCP)
- Mantener conversaciones naturales
- Actuar solo cuando es necesario

¬°Disfruta de tu nuevo asistente IA!